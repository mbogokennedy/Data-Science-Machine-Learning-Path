{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as seabornInstance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "df = pd.read_csv('merged_data24.04.2019.csv')\n",
    "# df1.head()\n",
    "\n",
    "df2 = pd.read_csv('world_country_region.csv', encoding='Latin-1')\n",
    "# df2.head()\n",
    "\n",
    "df3 = pd.merge(df1, df2, on='Country')\n",
    "df= df3.to_csv('df4.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the number of row and column\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"..\"].sum()\n",
    "\n",
    "s.isnull().values.any()\n",
    "df.isnull().sum().sum()\n",
    "df.isnull().sum()\n",
    "df['preTestScore'].where(df['postTestScore'] > 50)\n",
    "df[(df.T == \"..\").all()].sum()\n",
    "df[df['Emp_national']=='..'].sum()\n",
    "df.isin(['..']).sum().sum()\n",
    "len(df)\n",
    "replaces the value you want with null value\n",
    "# Author: Luke Schoen 2017\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "# Create DataFrame\n",
    "# df = pd.DataFrame(np.random.randn(10,2))\n",
    "\n",
    "# Populate with NaN values\n",
    "df = pd.DataFrame({'col1': ['1.111', '2.111', '3.111', '4.111'], 'col2': ['4.111', '5.111', np.NaN, '7.111'],\n",
    "'col3': ['8', '9', np.NaN, np.NaN], 'col4': ['12', '13', '14', '15']})\n",
    "\n",
    "# Round all values to 2 decimal places\n",
    "df.apply(functools.partial(np.round, decimals=2))\n",
    "\n",
    "# Populate DataFrame column 0 and indexed rows 2 to 6 with NaN values\n",
    "df.iloc[3:6,0] = np.nan\n",
    "\n",
    "def get_percentage_missing(series):\n",
    "    \"\"\" Calculates percentage of NaN values in DataFrame\n",
    "    :param series: Pandas DataFrame object\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    num = series.isnull().sum()\n",
    "    den = len(series)\n",
    "    return round(num/den, 2)\n",
    "\n",
    "# Only include columns that contain any NaN values\n",
    "df_with_any_null_values = df[df.columns[df.isnull().any()].tolist()]\n",
    "\n",
    "get_percentage_missing(df_with_any_null_values)\n",
    "\n",
    "# Show qty of each value in a Column \n",
    "# df.astype(str).groupby(['col1']).sum()\n",
    "\n",
    "# Show DataFrame\n",
    "df\n",
    "# df.head()\n",
    "\n",
    "# Show DataFrame info\n",
    "print(df.describe())\n",
    "print(df.info())\n",
    "\n",
    "# Iterate over columns in DataFrame and delete those with where >30% of the values are null/NaN\n",
    "for name, values in df_with_any_null_values.iteritems():\n",
    "    print(\"%r: %r\" % (name, values) )\n",
    "    if get_percentage_missing(df_with_any_null_values[name]) > 0.3:\n",
    "        print(\"Deleting Column %r: \" % (name) )\n",
    "        df_with_any_null_values.drop(name, axis=1, inplace=True)\n",
    "        \n",
    "# Iterate over columns in DataFrame and delete rows of columns where any values are null/NaN\n",
    "for name, values in df_with_any_null_values.iteritems():\n",
    "    if name != \"id\":\n",
    "        if get_percentage_missing(df_with_any_null_values[name]) < 0.01:\n",
    "            print(\"Retained Column: %r, but removed its null and NaN valued rows\" % (name) )\n",
    "            print(\"BEFORE %r: %r\" % (name, values) )\n",
    "            df_with_any_null_values.dropna(axis=0, how=\"any\", subset=[name], inplace=True)\n",
    "            print(\"AFTER %r: %r\" % (name, values) )\n",
    "            \n",
    "# Select only Columns of certain types\n",
    "# http://pandas.pydata.org/pandas-docs/version/0.19.2/generated/pandas.DataFrame.select_dtypes.html\n",
    "df.select_dtypes(include=['int', 'float64', 'floating', 'number'], exclude=['O'])\n",
    "\n",
    "# # Iterate over Columns and perform modifications depending on the type\n",
    "# IMPORTANT NOTE: ENSURE ONLY USE AFTER REMOVE NAN VALUES\n",
    "for col in df.columns:\n",
    "    for name, values in df[col].iteritems():\n",
    "        # print(\"%r, %r\" % (name, values))\n",
    "        if(values.dtype == np.float64 or values.dtype == np.int64):\n",
    "            print(\"float or int type %r\" % (values.dtype))\n",
    "            # treat_numeric(df[name])\n",
    "        elif(df[name].dtype == np.str):\n",
    "            print(\"string type %r\" % (df[name].dtype))\n",
    "            #treat_str(df[y])\n",
    "        elif(df[name].dtype == np.object):\n",
    "            print(\"object type %r\" % (df[name].dtype))\n",
    "            #treat_object(df[name])\n",
    "        else:\n",
    "            print(\"other type %r\" % (values.dtype))\n",
    "df1 = df.replace('..', np.nan)\n",
    "df1.to_csv('modified.csv')\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         2590\n",
       "unique        2478\n",
       "top       1.09E+11\n",
       "freq             6\n",
       "Name: GFCF, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts the number of values in a column in a dataframe and returns its data type\n",
    "# # df1.info()\n",
    "# df1['GFCF'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GFCF                2590\n",
       "Pop                 3792\n",
       "Rd                  1532\n",
       "Emp_national_new    3798\n",
       "GFCFpc              3798\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  counts the number of values in a column in a dataframe. tail checks the last five\n",
    "df1.count().tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6103"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                 0\n",
       "Country                0\n",
       "Region                 0\n",
       "Income Group           0\n",
       "Year                   0\n",
       "Emp_national        1800\n",
       "GDPpc                301\n",
       "Emp_modelled         522\n",
       "GFCF                1208\n",
       "Pop                    6\n",
       "Rd                  2266\n",
       "Emp_national_new       0\n",
       "GFCFpc                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_missing = df1.isna()\n",
    "df1_missing.head()\n",
    "df1_num_missing = df1_missing.sum()\n",
    "df1_len = len(df1)\n",
    "\n",
    "#df1_num_missing/df1_len # to find the mean\n",
    "\n",
    "df1_num_missing #or use mean function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.389999999999999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1.isna().mean().round(4) * 100\n",
    "df3 = (df1_num_missing.sum())/(df1_len*12)\n",
    "df3.round(4) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emp_New_Modeled'] = df1['Emp_modelled']/df1['Pop']\n",
    "\n",
    "[data['Y2007'].sum(), # Total sum of the column values\n",
    " data['Y2007'].mean(), # Mean of the column values\n",
    " data['Y2007'].median(), # Median of the column values\n",
    " data['Y2007'].nunique(), # Number of unique entries\n",
    " data['Y2007'].max(), # Maximum of the column values\n",
    " data['Y2007'].min()]\n",
    "\n",
    "# data.iloc[:, [0,1,20,22]]\n",
    "\n",
    "# Deleting columns\n",
    "# Delete the \"Area\" column from the dataframe\n",
    "data = data.drop(\"Area\", axis=1)\n",
    "# alternatively, delete columns using the columns parameter of drop\n",
    "data = data.drop(columns=\"area\")\n",
    "# Delete the Area column from the dataframe in place\n",
    "# Note that the original 'data' object is changed when inplace=True\n",
    "data.drop(\"Area\", axis=1, inplace=True). \n",
    "# Delete multiple columns from the dataframe\n",
    "data = data.drop([\"Y2001\", \"Y2002\", \"Y2003\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modified_25.csv')\n",
    "df['Pop'].dtypes\n",
    "\n",
    "df['GFCF_pc'] = df['GFCF']/df['Pop']\n",
    "df['Emp_Modeled_new'] = df['Emp_modelled']/100\n",
    "df.head()\n",
    "df1 = df.replace(0, np.nan)\n",
    "df2 = df1.replace('0', np.nan)\n",
    "\n",
    "df['GDPpc_Log'] = np.log(df['GDPpc'])\n",
    "df['GFCFpc_Log'] = np.log(df['GFCF_pc'])\n",
    "df['Emp_modeled_Log'] = np.log(df['Emp_modelled'])\n",
    "df.replace(np.nan, 0.0)\n",
    "df.head()\n",
    "# out_array = np.log(in_array)\n",
    "\n",
    "df.head()\n",
    "df.shape\n",
    "ds= df.replace(np.nan, 0)\n",
    "ds.head()\n",
    "dfg = ds.groupby(['Region', 'Country'])\n",
    "dfg.first()\n",
    "\n",
    "# for i in ssh_countries:\n",
    "#     dc = ds[ds['Country'] == i]\n",
    "#     X = dc[['Emp_modelled', 'GFCFpc_Log', 'Rd']].values\n",
    "#     y = dc[['GDPpc_Log']].values\n",
    "#     regressor = LinearRegression()  \n",
    "#     regressor.fit(X, y)\n",
    "#     rd_coeff = regressor.coef_\n",
    "#     ls.append(rd_coeff)\n",
    "\n",
    "# da = pd.DataFrame([ssh_countries, ls]).T\n",
    "# da.columns = ['Country', 'Size of RD Coeff']\n",
    "# # da.sort_values(by='Size of RD Coeff', ascending = False)\n",
    "# da\n",
    "\n",
    "\n",
    "df.isnull().any()\n",
    "ds = df.fillna(method='ffill')\n",
    "\n",
    "for i, ds in dfg:\n",
    "    X = ds[['Emp_modelled', 'GFCFpc_Log', 'Rd']].values\n",
    "    y = ds['GDPpc_Log'].values\n",
    "    regressor = LinearRegression()  \n",
    "    regressor.fit(X, y)\n",
    "    coeff_df = regressor.coef_\n",
    "    ls.append(coeff_df)\n",
    "ls\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "# seabornInstance.distplot(ds['GDPpc_Log'])\n",
    "# seabornInstance.pairplot(ds)\n",
    "ds.corr()\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "dp = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "dp.head(25)\n",
    "dp.head(25).plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()\n",
    "df = pd.read_csv('modified_25.csv')\n",
    "df.head()\n",
    "df.shape\n",
    "ds= df.replace(np.nan, 0)\n",
    "ds.head()\n",
    "dfg = ds.groupby(['Region'])\n",
    "dfg.first()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X, y)\n",
    "\n",
    "coeff_df = pd.DataFrame(regressor.coef_)\n",
    "coeff_df\n",
    "# regressor.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
